{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Regular Expressions - Week 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '19', '42']\n"
     ]
    }
   ],
   "source": [
    "## Regular Expressions\n",
    "import re\n",
    "x = 'My 2 favorite numbers are 19 and 42'\n",
    "y = re.findall('[0-9]+', x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From:']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "z = 'From: Using the : character'\n",
    "a = re.findall('^F.+?:', z)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = 'From: raulguilherme97@live.com Sun Mar 12 15:14:16'\n",
    "atpos = data.find('@')\n",
    "print(atpos)\n",
    "sppos = data.find(' ')\n",
    "print(sppos)\n",
    "host = data[atpos+1 : sppos]\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['live.com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "lin = 'From: raulguilherme97@live.com Sun Mar 12 15:14:16'\n",
    "y = re.findall('@([^ ]*)', lin)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: Using the :']\n"
     ]
    }
   ],
   "source": [
    "x = 'From: Using the : character'\n",
    "y = re.findall('^F.+:', x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565909\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "hand = open(\"regex_sum_1760680.txt\")\n",
    "x=list()\n",
    "for line in hand:\n",
    "     y = re.findall('[0-9]+',line)\n",
    "     x = x+y\n",
    "\n",
    "sum=0\n",
    "for z in x:\n",
    "    sum = sum + int(z)\n",
    "\n",
    "print(sum)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Tecnologia em redes - Week 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80)) #host, port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 400 Bad Request\n",
      "Date: Sun, 12 Mar 2023 21:13:14 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Content-Length: 308\n",
      "Connection: close\n",
      "Content-Type: text/html; charset=iso-8859-1\n",
      "\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>400 Bad Request</title>\n",
      "</head><body>\n",
      "<h1>Bad Request</h1>\n",
      "<p>Your browser sent a request that this server could not understand.<br />\n",
      "</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.18 (Ubuntu) Server at do1.dr-chuck.com Port 80</address>\n",
      "</body></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\n\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if (len(data)<1):\n",
    "        break\n",
    "    print(data.decode())\n",
    "mysock.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Unicode Characters and Strings - Weeek 4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\n\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode())\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise 1\n",
    "\n",
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "html = urllib.request.urlopen('https://py4e-data.dr-chuck.net/comments_1760682.html').read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "sum=0\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('span')\n",
    "for tag in tags:\n",
    "    # Look at the parts of a tag\n",
    "    y=str(tag)\n",
    "    x= re.findall(\"[0-9]+\",y)\n",
    "    for i in x:\n",
    "        i=int(i)\n",
    "        sum=sum+i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise 2\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "position = int(input(\"Enter position:\"))-1\n",
    "count = int(input(\"Enter count:\"))\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "Sequence = []\n",
    "tags = soup('a')\n",
    "for i in range(count):\n",
    "    link = tags[position].get('href', None)\n",
    "    print(\"Retrieving:\",link)\n",
    "    Sequence.append(tags[position].contents[0])\n",
    "    html = urllib.request.urlopen(link, context=ctx).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = soup('a')\n",
    "    link = tags[position].get('href', None)\n",
    "print(Sequence[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Data on the web {XML} - Week 5* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "97\n",
      "90\n",
      "90\n",
      "88\n",
      "87\n",
      "87\n",
      "80\n",
      "79\n",
      "79\n",
      "78\n",
      "76\n",
      "76\n",
      "72\n",
      "72\n",
      "66\n",
      "66\n",
      "65\n",
      "65\n",
      "64\n",
      "61\n",
      "61\n",
      "59\n",
      "58\n",
      "57\n",
      "57\n",
      "54\n",
      "51\n",
      "49\n",
      "47\n",
      "40\n",
      "38\n",
      "37\n",
      "36\n",
      "36\n",
      "32\n",
      "25\n",
      "24\n",
      "22\n",
      "21\n",
      "19\n",
      "18\n",
      "18\n",
      "14\n",
      "12\n",
      "12\n",
      "9\n",
      "7\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "url = 'http://py4e-data.dr-chuck.net/comments_42.xml'\n",
    "\n",
    "uh = urllib.request.urlopen(url)\n",
    "data = uh.read()\n",
    "tree = ET.fromstring(data)\n",
    "lst = tree.findall('comments/comment/count')\n",
    "counts = tree.findall('.//count')\n",
    "\n",
    "for each in counts:\n",
    "    print(each.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2469\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "url = 'https://py4e-data.dr-chuck.net/comments_1760684.xml'\n",
    "\n",
    "uh = urllib.request.urlopen(url)\n",
    "data = uh.read()\n",
    "tree = ET.fromstring(data)\n",
    "lst = tree.findall('comments/comment/count')\n",
    "counts = tree.findall('.//count')\n",
    "total = 0\n",
    "for each in counts:\n",
    "    a = int((each.text))\n",
    "    total = total + a\n",
    "    \n",
    "print(total)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *JSON - JavaScript Object Notation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your first name is... Jane\n",
      "And the name your firts kid is... Alice Silva\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = \"\"\"\n",
    "{\n",
    "    \"firstName\": \"Jane\",\n",
    "    \"lastName\": \"Doe\",\n",
    "    \"hobbies\": [\"running\", \"sky diving\", \"singing\"],\n",
    "    \"age\": 35,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"firstName\": \"Alice\",\n",
    "            \"lastName\": \"Silva\",\n",
    "            \"age\": 6\n",
    "        },\n",
    "        {\n",
    "            \"firstName\": \"Bob\",\n",
    "            \"lastName\": \"Silva\",\n",
    "            \"age\": 8\n",
    "        }\n",
    "    ]\n",
    "}\"\"\"\n",
    "\n",
    "info = json.loads(data)\n",
    "print('Your first name is...', info[\"firstName\"])\n",
    "print('And the name your firts kid is...', info[\"children\"][0][\"firstName\"], info[\"children\"][0][\"lastName\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = json.loads(data)\n",
    "for item in info:\n",
    "    print('a', item['firstName'])\n",
    "    print('a', item['lastName'])\n",
    "    print('a', item['age'])\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*API'S*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GeoJSON --> Google maps\n",
    "#Twitter API --> Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://py4e-data.dr-chuck.net/comments_1760685.json\n",
      "Retrieved 1720 characters\n",
      "Count: 50\n",
      "Sum: 2280\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#exercicio 1\n",
    "#insira: https://py4e-data.dr-chuck.net/comments_1760685.json\n",
    "# ou insira: https://py4e-data.dr-chuck.net/comments_42.json\n",
    "\n",
    "import urllib.request, json\n",
    "\n",
    "address = input('Enter location: ')\n",
    "print('Retrieving', address)\n",
    "with urllib.request.urlopen(address) as url:\n",
    "    raw = json.loads(url.read().decode())\n",
    "\n",
    "print('Retrieved', len(str(raw)), 'characters')\n",
    "data = raw.get(\"comments\")\n",
    "#print(data)\n",
    "num = total = 0\n",
    "for i in range(len(data)):\n",
    "    tmp = data[i]\n",
    "    value = tmp.get(\"count\")\n",
    "    num = num + 1\n",
    "    total = total + int(value)\n",
    "print(\"Count:\",num)\n",
    "print(\"Sum:\",total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving http://py4e-data.dr-chuck.net/json?address=Tarrant+County+College&key=42\n",
      "Retrieved 2162 characters\n",
      "Place id  ChIJx75YhhRxToYRlnE-DPCLXS8\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json\n",
    "import ssl\n",
    "\n",
    "api_key = False\n",
    "\n",
    "if api_key is False:\n",
    "    api_key = 42\n",
    "    serviceurl = 'http://py4e-data.dr-chuck.net/json?'\n",
    "else :\n",
    "    serviceurl = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    parms = dict()\n",
    "    parms['address'] = address\n",
    "    if api_key is not False: parms['key'] = api_key\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters')\n",
    "\n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        js = None\n",
    "\n",
    "    if not js or 'status' not in js or js['status'] != 'OK':\n",
    "        print('==== Failure To Retrieve ====')\n",
    "        print(data)\n",
    "        continue\n",
    "\n",
    "    # print(json.dumps(js, indent=4))\n",
    "\n",
    "    pid = js['results'][0]['place_id']\n",
    "    print('Place id ',pid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
